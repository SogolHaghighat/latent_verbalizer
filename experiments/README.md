# Categorization experiments using LlaMa
This section contains the code for postprocessing and visualizing the result of the categorization experiment. Generated captions from each layer are further processed using [Llama-3.1-70B-Instruct](https://huggingface.co/meta-llama/Llama-3.1-70B-Instruct) model to extract visually detectable attributes from each caption. The result of this analysis is summarized in this figure.

![](framework/SAC_5_percent.png)
  | 
## Data

The data folder in this repository contains generated captions per every layer for all samples (5K samples in Karpathy test split) and results of categorization experiments after postprocessing that contains the percentage of each category per every layer. This data is used to generate the plot.

The data folder (under data/interpret) also contains the results of batch caption generation and LLM categorization of the same batch (10% of the whole set). This data can be directly reproduced by following the instructions of the main package.

## Prompting Experiments for the Categorization Task

Several experiments to prompt the language model for this task have been carried out and the presented analysis showed the best results. Followings have been tested:
  1. One caption at a time
      - Generate one label per token/ part of caption: 
            resulted in generating explanations and very fine-grained labels
      - **Generate three labels per token/part of caption (selected approach)**: 
            context is mainly preserved,
            when there is repetition in generated caption, the model can get stuck in a loop. these samples follow a pattern and can be fixed by post-processing. removing them result in ~1.32% data loss. opted for  removal at this stage  (observation: mostly occur in early layers).
            prompt is adapted from previous experiment to avoid generating explanation and give the model a chance to generate more generic super classes and assign more fine-grained labels for label 2 and 3 for each token. 
            further merging of the recognized classes is performed to give an overall view of what visual classes are detected at which layers
      - Word by word labeling: 
            context gets lost - requires further adjusting the prompt
            example: ice cream â†’ ice + cream (first labeled as UNKNOWN, second as food, this results in a noisy output and requires further post-processing.)
      - Two stage approach: segmentation of the caption one by one using LLM and then providing the results of the segmentation and full caption (for more context) to LLM asking for labeling
            very time consuming experiment and context still gets lost to a large degree!
  2. All captions of from an image at once (model gets stuck in a loop and will not reach the end of a full stack of captions for a given sample - inconclusive results!)

## Postprocessing

The language model was prompted to generate responses in a form of a dictionary however, the following observations were made:
- About 1.32% of of the generated responses did no followw the dictionary format and not transformable directly (they can be manually processed but during the experimentations, they have been removed.)
- Even though the LLM was prompted to not explain the given response, there was a single case of generated explanation and hence removed from the analysis.
- The language model in some cases used the plural or similar word for the category names. For that, all the generated categories were extracted and merged. (e.g. location, locations, places -> location)

### Update: Classification results for LLaVA model fine-tuned on COCO2017

![](framework/SAC_5_percent_llava.png)